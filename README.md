The report would be uploaded before 15 of September

# Extractive Text summarization

Code used for my master thesis, It explores 5 difference methods of extractive text summarization in 3 different datasets. The code + commentaries are different notebooks.
It was developed using google colab with google drive

This code uses 3 datasets:
- Dataset 1: https://www.kaggle.com/sunnysai12345/news-summary
- Dataset 2: https://www.tensorflow.org/datasets/catalog/cnn_dailymail or https://cs.nyu.edu/~kcho/DMQA/ both CNN and Daily mail stories
- Dataset 3: https://www.tensorflow.org/datasets/catalog/multi_news or https://github.com/Alex-Fabbri/Multi-News

The methods explored are:
1. First k sentences (modified lead-3-sentences)
2. Word frequency
3. TextRank
4. Latent Semantic Analysis (LSA)
5. [Presumm](https://github.com/nlpyang/PreSumm)

There are different notebooks:
- datasets.ipynb: Initial preprocessing
- dataset1.ipynb: Methods 1-4 for dataset 1
- dataset2.ipynb: Methods 1-4 for dataset 2
- dataset3.ipynb: Methods 1-4 for dataset 3
- Preprocessing_PreSumm.ipynb Preprocessing for method PreSumm
- PreSumm.ipynb: Method 5 for all datasets


The results are evaluated Using the F1-Score of ROUGUE-1, ROUGE-2 and ROUGE-L

For more details specific notebook and see the report.

The extra code needed have also been included. PresSumm source code from https://github.com/nlpyang/PreSumm with little modifications, stanford-corenlp-full-2018-10-05, PyTLDR library and the datasets as txt files.

Author: Andr√©s Escalante Ariza
All references are in the report and the code
